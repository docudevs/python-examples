{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee894809",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3930ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the SDK if needed\n",
    "# %pip install docu-devs-api-client pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ed263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from docudevs import DocuDevsClient\n",
    "\n",
    "API_KEY = os.getenv(\"DOCUDEVS_API_KEY\", \"your-api-key-here\")\n",
    "client = DocuDevsClient(token=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe222507",
   "metadata": {},
   "source": [
    "## First: Process a Document\n",
    "\n",
    "Operations work on completed jobs, so let's process something first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process a document\n",
    "with open(\"docs/invoice.pdf\", \"rb\") as f:\n",
    "    invoice_bytes = f.read()\n",
    "\n",
    "class Invoice(BaseModel):\n",
    "    invoice_number: str\n",
    "    date: str\n",
    "    vendor: str\n",
    "    total: float\n",
    "    line_items: list[dict] = Field(default_factory=list)\n",
    "\n",
    "job_id = await client.submit_and_process_document(\n",
    "    document=invoice_bytes,\n",
    "    document_mime_type=\"application/pdf\",\n",
    "    schema=json.dumps(Invoice.model_json_schema()),\n",
    "    prompt=\"Extract all invoice details.\"\n",
    ")\n",
    "\n",
    "result = await client.wait_until_ready(job_id, result_format=\"json\")\n",
    "print(f\"Job completed: {job_id}\")\n",
    "print(f\"Extracted: {json.dumps(result, indent=2)[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06d9cb",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Was the extraction accurate? Error analysis examines the results and flags potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run error analysis on the completed job\n",
    "analysis = await client.submit_and_wait_for_error_analysis(\n",
    "    job_guid=job_id,\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "print(\"=== Error Analysis ===\")\n",
    "\n",
    "# Parse the result JSON\n",
    "if hasattr(analysis, 'result') and analysis.result:\n",
    "    result_data = json.loads(analysis.result) if isinstance(analysis.result, str) else analysis.result\n",
    "    \n",
    "    # Display overall quality\n",
    "    quality = result_data.get('extraction_quality', 'unknown')\n",
    "    confidence = result_data.get('overall_confidence', 0)\n",
    "    print(f\"Quality: {quality}\")\n",
    "    print(f\"Overall confidence: {confidence:.0%}\")\n",
    "    \n",
    "    # Display field analysis\n",
    "    fields = result_data.get('field_analysis', [])\n",
    "    if fields:\n",
    "        print(f\"\\nField Analysis ({len(fields)} fields):\")\n",
    "        for field in fields:\n",
    "            name = field.get('field_name', 'unknown')\n",
    "            conf = field.get('confidence', 0)\n",
    "            issues = field.get('issues', [])\n",
    "            status = \"‚ö†Ô∏è\" if issues else \"‚úì\"\n",
    "            print(f\"  {status} {name}: {conf:.0%} confidence\")\n",
    "            for issue in issues:\n",
    "                print(f\"      Issue: {issue}\")\n",
    "            for suggestion in field.get('suggestions', []):\n",
    "                print(f\"      Suggestion: {suggestion}\")\n",
    "    \n",
    "    # Display OCR issues if any\n",
    "    ocr_issues = result_data.get('ocr_issues', [])\n",
    "    if ocr_issues:\n",
    "        print(f\"\\nOCR Issues ({len(ocr_issues)}):\")\n",
    "        for issue in ocr_issues:\n",
    "            print(f\"  - {issue.get('type')}: {issue.get('description')}\")\n",
    "else:\n",
    "    print(\"No analysis result available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de72f4",
   "metadata": {},
   "source": [
    "## Generative Tasks: Ask Questions About Documents\n",
    "\n",
    "Generative tasks let you ask questions about document content. They work on **OCR jobs**\n",
    "(not extraction jobs) since they need the raw OCR text to reason about.\n",
    "\n",
    "Let's OCR the same invoice and then ask questions about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba692b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, OCR the document (generative tasks need OCR jobs, not extraction jobs)\n",
    "ocr_job_id = await client.submit_and_ocr_document(\n",
    "    document=invoice_bytes,\n",
    "    document_mime_type=\"application/pdf\",\n",
    "    ocr=\"DEFAULT\",\n",
    "    ocr_format=\"markdown\"\n",
    ")\n",
    "await client.wait_until_ready(ocr_job_id)\n",
    "print(f\"OCR job completed: {ocr_job_id}\")\n",
    "\n",
    "# Now ask a question\n",
    "question_result = await client.submit_and_wait_for_generative_task(\n",
    "    parent_job_id=ocr_job_id,\n",
    "    prompt=\"What payment terms are mentioned in this invoice? If there's a due date, when is it?\",\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "if hasattr(question_result, 'result'):\n",
    "    result_data = json.loads(question_result.result) if isinstance(question_result.result, str) else question_result.result\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(result_data.get('generated_text', 'No response'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary (uses the same OCR job)\n",
    "summary_result = await client.submit_and_wait_for_generative_task(\n",
    "    parent_job_id=ocr_job_id,\n",
    "    prompt=\"Provide a one-paragraph summary of this invoice suitable for an expense report.\",\n",
    "    temperature=0.3,  # Lower = more focused/deterministic\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "if hasattr(summary_result, 'result'):\n",
    "    result_data = json.loads(summary_result.result) if isinstance(summary_result.result, str) else summary_result.result\n",
    "    print(\"Summary:\")\n",
    "    print(result_data.get('generated_text', 'No response'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608f922",
   "metadata": {},
   "source": [
    "## Multiple Questions on One Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7116b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What company issued this invoice?\",\n",
    "    \"What is the total amount due?\",\n",
    "    \"How many line items are there?\",\n",
    "    \"What is the most expensive item?\"\n",
    "]\n",
    "\n",
    "print(\"=== Document Q&A ===\")\n",
    "for question in questions:\n",
    "    answer = await client.submit_and_wait_for_generative_task(\n",
    "        parent_job_id=ocr_job_id,\n",
    "        prompt=f\"Based on this invoice, answer briefly: {question}\"\n",
    "    )\n",
    "    \n",
    "    if hasattr(answer, 'result'):\n",
    "        result_data = json.loads(answer.result) if isinstance(answer.result, str) else answer.result\n",
    "        print(f\"\\nQ: {question}\")\n",
    "        print(f\"A: {result_data.get('generated_text', 'No response')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856c16a",
   "metadata": {},
   "source": [
    "## Check Operation Status\n",
    "\n",
    "For longer operations, you can check status and see all operations run on a job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87871a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all operations for the OCR job (which has generative tasks)\n",
    "status = await client.get_operation_status(job_guid=ocr_job_id)\n",
    "\n",
    "print(f\"Operations on OCR job {ocr_job_id}:\")\n",
    "if hasattr(status, 'operations'):\n",
    "    for op in status.operations:\n",
    "        print(f\"  - {op.operation_type}: {op.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb968afc",
   "metadata": {},
   "source": [
    "## Complete Workflow Example\n",
    "\n",
    "Here's a workflow that combines extraction (for structured data), error analysis, \n",
    "and generative tasks (for summaries). Note that extraction and generative tasks \n",
    "use different job types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3804e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_and_analyze(document_bytes, mime_type, schema):\n",
    "    \"\"\"Process a document with extraction, error analysis, and summary.\"\"\"\n",
    "    \n",
    "    # Step 1: Extract structured data\n",
    "    print(\"Step 1: Extracting structured data...\")\n",
    "    extraction_job_id = await client.submit_and_process_document(\n",
    "        document=document_bytes,\n",
    "        document_mime_type=mime_type,\n",
    "        schema=schema,\n",
    "        prompt=\"Extract all information according to the schema.\"\n",
    "    )\n",
    "    extraction = await client.wait_until_ready(extraction_job_id, result_format=\"json\")\n",
    "    print(f\"  ‚úì Extracted data\")\n",
    "    \n",
    "    # Step 2: Error analysis (works on extraction jobs)\n",
    "    print(\"Step 2: Running error analysis...\")\n",
    "    try:\n",
    "        analysis = await client.submit_and_wait_for_error_analysis(job_guid=extraction_job_id, timeout=60)\n",
    "        analysis_data = json.loads(analysis.result) if hasattr(analysis, 'result') and isinstance(analysis.result, str) else {}\n",
    "        confidence = analysis_data.get('overall_confidence', 'N/A')\n",
    "        quality = analysis_data.get('extraction_quality', 'unknown')\n",
    "        print(f\"  ‚úì Quality: {quality}, Confidence: {confidence}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Error analysis skipped: {e}\")\n",
    "        confidence = \"unknown\"\n",
    "    \n",
    "    # Step 3: OCR the document for generative tasks\n",
    "    print(\"Step 3: OCR for generative task...\")\n",
    "    ocr_job_id = await client.submit_and_ocr_document(\n",
    "        document=document_bytes,\n",
    "        document_mime_type=mime_type,\n",
    "        ocr=\"DEFAULT\",\n",
    "        ocr_format=\"markdown\"\n",
    "    )\n",
    "    await client.wait_until_ready(ocr_job_id)\n",
    "    print(f\"  ‚úì OCR complete\")\n",
    "    \n",
    "    # Step 4: Generate summary (requires OCR job)\n",
    "    print(\"Step 4: Generating summary...\")\n",
    "    summary = await client.submit_and_wait_for_generative_task(\n",
    "        parent_job_id=ocr_job_id,\n",
    "        prompt=\"Summarize this document in 2-3 sentences.\",\n",
    "        timeout=60\n",
    "    )\n",
    "    summary_text = \"\"\n",
    "    if hasattr(summary, 'result'):\n",
    "        summary_data = json.loads(summary.result) if isinstance(summary.result, str) else summary.result\n",
    "        summary_text = summary_data.get('generated_text', '')\n",
    "    print(f\"  ‚úì Summary generated\")\n",
    "    \n",
    "    return {\n",
    "        \"extraction_job_id\": extraction_job_id,\n",
    "        \"ocr_job_id\": ocr_job_id,\n",
    "        \"extraction\": extraction,\n",
    "        \"confidence\": confidence,\n",
    "        \"summary\": summary_text\n",
    "    }\n",
    "\n",
    "# Run the workflow\n",
    "schema = json.dumps(Invoice.model_json_schema())\n",
    "result = await process_and_analyze(invoice_bytes, \"application/pdf\", schema)\n",
    "\n",
    "print(\"\\n=== Results ===\")\n",
    "print(f\"Extraction Job: {result['extraction_job_id']}\")\n",
    "print(f\"OCR Job: {result['ocr_job_id']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(f\"Summary: {result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a5c32",
   "metadata": {},
   "source": [
    "## Tips for Operations\n",
    "\n",
    "1. **Error analysis works on extraction jobs**: Use it to validate structured extraction results\n",
    "\n",
    "2. **Generative tasks require OCR jobs**: If you need both extraction and generative tasks, \n",
    "   you'll need two jobs (or use OCR-only and do extraction via generative prompts)\n",
    "\n",
    "3. **Be specific with generative prompts**: \"Summarize in 2 sentences\" beats \"summarize\"\n",
    "\n",
    "4. **Use temperature for control**: Lower values (0.1-0.3) = more deterministic; \n",
    "   higher values (0.7-0.9) = more creative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de738b",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "You've now seen the main features of DocuDevs:\n",
    "\n",
    "- **[Basic Extraction](01-basic-extraction.ipynb)**: Extract structured data with Pydantic schemas\n",
    "- **[Map-Reduce](02-map-reduce.ipynb)**: Handle long documents by chunking\n",
    "- **[Knowledge Search](03-knowledge-search.ipynb)**: Enrich extractions with your reference data\n",
    "- **Operations** (this notebook): Error analysis and follow-up questions\n",
    "\n",
    "Happy extracting! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
